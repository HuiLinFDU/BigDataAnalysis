{"cells":[{"cell_type":"markdown","metadata":{"id":"kPt5q27L5557"},"source":["## Collaborative Filtering\n","\n","source: https://colab.research.google.com/drive/1UWeDiyXiwDDqe7ksN2kt-myHsuSLObv8?usp=sharing"]},{"cell_type":"markdown","metadata":{"id":"p0-YhEpP_Ds-"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"Zsj5WYpR9QId"},"source":["Let's set up Spark on your Colab environment.  Run the cell below!"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k-qHai2252mI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743721022728,"user_tz":420,"elapsed":8652,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"07d0a529-27e4-47dd-bf06-0742e5f96a73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n","Requirement already satisfied: pydrive2 in /usr/local/lib/python3.11/dist-packages (1.21.3)\n","Requirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.11/dist-packages (from pydrive2) (2.164.0)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pydrive2) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.11/dist-packages (from pydrive2) (6.0.2)\n","Requirement already satisfied: cryptography<44 in /usr/local/lib/python3.11/dist-packages (from pydrive2) (43.0.3)\n","Requirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from pydrive2) (24.2.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44->pydrive2) (1.17.1)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (0.22.0)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (2.38.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (0.2.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (2.24.2)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (4.1.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->pydrive2) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->pydrive2) (0.4.2)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->pydrive2) (4.9)\n","Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->pydrive2) (1.17.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44->pydrive2) (2.22)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.69.2)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (5.29.4)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.26.1)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.5->pydrive2) (5.5.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.12.5->pydrive2) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2025.1.31)\n","openjdk-8-jdk-headless is already the newest version (8u442-b06~us1-0ubuntu1~22.04).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"]}],"source":["!pip install pyspark\n","#--- Warning Handling  Add by Hui Lin 04/02/2025\n","#!pip install -U -q PyDrive\n","!pip install pydrive2\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""]},{"cell_type":"markdown","metadata":{"id":"PUUjUvXe3Sjk"},"source":["Now we authenticate a Google Drive client to download the files we will be processing in our Spark job.\n","\n","**Make sure to follow the interactive instructions.**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lRElWs_x2mGh","executionInfo":{"status":"ok","timestamp":1743721043743,"user_tz":420,"elapsed":14209,"user":{"displayName":"林辉","userId":"00815086233424508369"}}},"outputs":[],"source":["#--- Warning Handling  Add by Hui Lin 04/02/2025\n","#from pydrive.auth import GoogleAuth\n","#from pydrive.drive import GoogleDrive\n","from pydrive2.auth import GoogleAuth\n","from pydrive2.drive import GoogleDrive\n","\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QHsFTGUy2n1c","executionInfo":{"status":"ok","timestamp":1743721054059,"user_tz":420,"elapsed":4187,"user":{"displayName":"林辉","userId":"00815086233424508369"}}},"outputs":[],"source":["id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.training')\n","\n","id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.test')\n","\n","id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.item')"]},{"cell_type":"markdown","metadata":{"id":"qwtlO4_m_LbQ"},"source":["If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n","\n","Next, we import some of the common libraries needed for our task."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"twk-K-jilWK7","executionInfo":{"status":"ok","timestamp":1743721155632,"user_tz":420,"elapsed":1236,"user":{"displayName":"林辉","userId":"00815086233424508369"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import pyspark\n","from pyspark.sql import *\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf"]},{"cell_type":"markdown","metadata":{"id":"BtrJlMBt1Ela"},"source":["Let's initialize the Spark context."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Vm3sAVeK1EDZ","executionInfo":{"status":"ok","timestamp":1743721168249,"user_tz":420,"elapsed":9582,"user":{"displayName":"林辉","userId":"00815086233424508369"}}},"outputs":[],"source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"kAYRX2PMm0L6"},"source":["### Data Loading"]},{"cell_type":"markdown","metadata":{"id":"7hXdMR6wnEIM"},"source":["In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n","\n","We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5K93ABEy9Zlo","executionInfo":{"status":"ok","timestamp":1743721182688,"user_tz":420,"elapsed":5569,"user":{"displayName":"林辉","userId":"00815086233424508369"}}},"outputs":[],"source":["schema_ratings = StructType([\n","    StructField(\"user_id\", IntegerType(), False),\n","    StructField(\"item_id\", IntegerType(), False),\n","    StructField(\"rating\", IntegerType(), False),\n","    StructField(\"timestamp\", IntegerType(), False)])\n","\n","schema_items = StructType([\n","    StructField(\"item_id\", IntegerType(), False),\n","    StructField(\"movie\", StringType(), False)])\n","\n","training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n","test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n","items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MC_m1oygCoEm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743721367172,"user_tz":420,"elapsed":3170,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"c84dfd6e-4def-4afe-c89c-e2705ea9bb42"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- user_id: integer (nullable = true)\n"," |-- item_id: integer (nullable = true)\n"," |-- rating: integer (nullable = true)\n"," |-- timestamp: integer (nullable = true)\n","\n","training records: 80000\n","+-------+-------+------+---------+\n","|user_id|item_id|rating|timestamp|\n","+-------+-------+------+---------+\n","|1      |1      |5     |874965758|\n","|1      |2      |3     |876893171|\n","|1      |3      |4     |878542960|\n","|1      |4      |3     |876893119|\n","|1      |5      |3     |889751712|\n","+-------+-------+------+---------+\n","only showing top 5 rows\n","\n"]}],"source":["training.printSchema()\n","#--- take a look by Hui Lin 04/02/2025\n","print('training records:',training.count())\n","training.show(5, truncate=False)"]},{"cell_type":"code","source":["#--- about test dataset add by Hui Lin 04/02/2025\n","test.printSchema()\n","print('test records:',test.count())\n","test.show(5, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lkGGoKC5M4L","executionInfo":{"status":"ok","timestamp":1743721438962,"user_tz":420,"elapsed":357,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"2fef2701-d0bc-42cb-e4ee-9cac913178b0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- user_id: integer (nullable = true)\n"," |-- item_id: integer (nullable = true)\n"," |-- rating: integer (nullable = true)\n"," |-- timestamp: integer (nullable = true)\n","\n","test records: 20000\n","+-------+-------+------+---------+\n","|user_id|item_id|rating|timestamp|\n","+-------+-------+------+---------+\n","|1      |6      |5     |887431973|\n","|1      |10     |3     |875693118|\n","|1      |12     |5     |878542960|\n","|1      |14     |5     |874965706|\n","|1      |17     |3     |875073198|\n","+-------+-------+------+---------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"81Vgo4ovCqtQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743721474547,"user_tz":420,"elapsed":849,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"9180b0c8-7e7c-41c8-9cd4-3ef0acc28206"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- item_id: integer (nullable = true)\n"," |-- movie: string (nullable = true)\n","\n","items records: 1682\n","+-------+-----------------+\n","|item_id|movie            |\n","+-------+-----------------+\n","|1      |Toy Story (1995) |\n","|2      |GoldenEye (1995) |\n","|3      |Four Rooms (1995)|\n","|4      |Get Shorty (1995)|\n","|5      |Copycat (1995)   |\n","+-------+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["items.printSchema()\n","#--- take a look by Hui Lin 04/02/2025\n","print('items records:',items.count())\n","items.show(5, truncate=False)"]},{"cell_type":"code","source":["# Merge dataset into One by Hui Lin 04/03/2025\n","full_data = training.union(test)\n","#--- take a look\n","print('full records:',full_data.count())\n","full_data.show(5, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11MaTKQm52Bl","executionInfo":{"status":"ok","timestamp":1743721654815,"user_tz":420,"elapsed":1516,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"f49ae10b-e88e-4fdb-bcf7-93152489d153"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["full records: 100000\n","+-------+-------+------+---------+\n","|user_id|item_id|rating|timestamp|\n","+-------+-------+------+---------+\n","|1      |1      |5     |874965758|\n","|1      |2      |3     |876893171|\n","|1      |3      |4     |878542960|\n","|1      |4      |3     |876893119|\n","|1      |5      |3     |889751712|\n","+-------+-------+------+---------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"CRaF2A_j_nC7"},"source":["### Your task"]},{"cell_type":"markdown","metadata":{"id":"zM9w2aUvJ7KN"},"source":["Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"8XZaH16t_CIw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743721860837,"user_tz":420,"elapsed":5795,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"7f19f051-9978-42e7-9f36-7275701cb388"},"outputs":[{"output_type":"stream","name":"stdout","text":["training dataset rating number: 80000\n","test dataset rating number: 20000\n","movies number: 1682\n","+-------+-----------------+-----------------+------------------+-------------------+\n","|summary|          user_id|          item_id|            rating|          timestamp|\n","+-------+-----------------+-----------------+------------------+-------------------+\n","|  count|            80000|            80000|             80000|              80000|\n","|   mean|         525.1657|         425.7052|           3.52835|8.835644684032375E8|\n","| stddev|255.9495596220549|331.3839356537554|1.1185646683748185|  5318610.832663398|\n","|    min|                1|                1|                 1|          874724727|\n","|    max|              943|             1682|                 5|          893286638|\n","+-------+-----------------+-----------------+------------------+-------------------+\n","\n","+-------+------------------+------------------+------------------+-----------------+\n","|summary|           user_id|           item_id|            rating|        timestamp|\n","+-------+------------------+------------------+------------------+-----------------+\n","|  count|             20000|             20000|             20000|            20000|\n","|   mean|         211.76095|         424.82985|            3.5359|8.8338638383015E8|\n","| stddev|121.64689968720005|328.45290676834566|1.1536800851565987|5441470.926358439|\n","|    min|                 1|                 1|                 1|        874724710|\n","|    max|               462|              1591|                 5|        893277702|\n","+-------+------------------+------------------+------------------+-----------------+\n","\n"]}],"source":["# YOUR CODE HERE by Hui Lin 04/02/2025\n","# Get the counts of ratings\n","num_ratings_train = training.count()\n","num_ratings_test = test.count()\n","\n","# Get the counts of movies\n","num_movies = items.count()\n","\n","# take a look\n","print(f\"training dataset rating number: {num_ratings_train}\")\n","print(f\"test dataset rating number: {num_ratings_test}\")\n","print(f\"movies number: {num_movies}\")\n","\n","training.describe().show()\n","test.describe().show()"]},{"cell_type":"code","source":["#--- Advanced checking by Hui Lin 04/03/2025\n","from pyspark.sql.functions import skewness, kurtosis\n","\n","#--- Numerical column extension statistics\n","full_data.select(\n","    \"rating\",\n","    \"user_id\",\n","    \"item_id\"\n",").summary(\n","    \"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"\n",").show()\n","\n","#--- distribution morphology\n","full_data.agg(\n","    skewness(\"rating\").alias(\"rating_Skewness\"),\n","    kurtosis(\"rating\").alias(\"rating_kurtosis\")\n",").show()\n","\n","#---Distribution of user ratings\n","user_activity = full_data.groupBy(\"user_id\").count()\n","user_activity.describe(\"count\").show()\n","\n","#---Distribution of movie rated\n","movie_popularity = full_data.groupBy(\"item_id\").count()\n","movie_popularity.describe(\"count\").show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwqrbZVV7TRX","executionInfo":{"status":"ok","timestamp":1743722146637,"user_tz":420,"elapsed":3395,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"f4aa8835-b456-4153-9226-ede97b5a918f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------------------+-----------------+-----------------+\n","|summary|            rating|          user_id|          item_id|\n","+-------+------------------+-----------------+-----------------+\n","|  count|            100000|           100000|           100000|\n","|   mean|           3.52986|        462.48475|        425.53013|\n","| stddev|1.1256735991443156|266.6144201275091|330.7983563255874|\n","|    min|                 1|                1|                1|\n","|    25%|                 3|              254|              175|\n","|    50%|                 4|              447|              322|\n","|    75%|                 4|              682|              631|\n","|    max|                 5|              943|             1682|\n","+-------+------------------+-----------------+-----------------+\n","\n","+-------------------+-------------------+\n","|    rating_Skewness|    rating_kurtosis|\n","+-------------------+-------------------+\n","|-0.5101362970258883|-0.4127785351130453|\n","+-------------------+-------------------+\n","\n","+-------+------------------+\n","|summary|             count|\n","+-------+------------------+\n","|  count|               943|\n","|   mean|106.04453870625663|\n","| stddev|100.93174276633502|\n","|    min|                20|\n","|    max|               737|\n","+-------+------------------+\n","\n","+-------+-----------------+\n","|summary|            count|\n","+-------+-----------------+\n","|  count|             1682|\n","|   mean|59.45303210463734|\n","| stddev|80.38384561004933|\n","|    min|                1|\n","|    max|              583|\n","+-------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["#--- Value checking by Hui Lin 04/03/2025\n","from pyspark.sql.functions import col, sum\n","from pyspark.sql.functions import year, month\n","from pyspark.sql.functions import col, from_unixtime\n","\n","\n","#--- Any null value ？\n","full_data.select(\n","    [sum(col(c).isNull().cast(\"int\")).alias(c) for c in training.columns]\n",").show()\n","\n","#--- Any abnormal rating range ?\n","abn_rate=full_data.filter(\n","    (col(\"rating\") < 1) | (col(\"rating\") > 5)\n",").count()\n","print('the number of abnormal rating:',abn_rate)\n","\n","\n","#--- Number of ratings by time(Year + Month)\n","time_analysis = training.withColumn(\"date\", from_unixtime(col(\"timestamp\"))) \\\n","                       .withColumn(\"year\", year(col(\"date\"))) \\\n","                       .withColumn(\"month\", month(col(\"date\"))) \\\n","                       .groupBy(\"year\", \"month\").count()\n","\n","#--- take a look\n","time_analysis.orderBy(\"year\", \"month\").show()\n","year_distribution = time_analysis.groupBy(\"year\").count().orderBy(\"year\")\n","print(\"Statistics by year:\")\n","year_distribution.show(year_distribution.count(), truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xux_45fL8hKP","executionInfo":{"status":"ok","timestamp":1743722901152,"user_tz":420,"elapsed":1830,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"a8a5867f-ba9e-4d76-98b4-c11b60709e82"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-------+------+---------+\n","|user_id|item_id|rating|timestamp|\n","+-------+-------+------+---------+\n","|      0|      0|     0|        0|\n","+-------+-------+------+---------+\n","\n","the number of abnormal rating: 0\n","+----+-----+-----+\n","|year|month|count|\n","+----+-----+-----+\n","|1997|    9| 5077|\n","|1997|   10| 8127|\n","|1997|   11|19197|\n","|1997|   12| 9813|\n","|1998|    1|11386|\n","|1998|    2| 8968|\n","|1998|    3|10239|\n","|1998|    4| 7193|\n","+----+-----+-----+\n","\n","Statistics by year:\n","+----+-----+\n","|year|count|\n","+----+-----+\n","|1997|4    |\n","|1998|4    |\n","+----+-----+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"wpsaYOqRxar2"},"source":["Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oitav_xhQD9w","executionInfo":{"status":"ok","timestamp":1743725040100,"user_tz":420,"elapsed":15155,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"a20d77a7-546a-4b6f-bae3-a2955fa4ca0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The RMSE is : 0.7420074798189229\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|user_id|recommendations                                                                                                                                                                         |\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1      |[{1449, 4.9319506}, {1368, 4.8544674}, {169, 4.8379045}, {119, 4.817549}, {408, 4.804264}, {114, 4.7831445}, {1643, 4.724744}, {1467, 4.710329}, {127, 4.6748047}, {12, 4.6719923}]     |\n","|3      |[{320, 4.8944516}, {1368, 4.789897}, {1491, 4.5189085}, {1203, 4.5146813}, {1629, 4.297292}, {634, 4.295074}, {408, 4.2890987}, {902, 4.281837}, {1643, 4.280994}, {867, 4.242356}]     |\n","|5      |[{169, 4.5924625}, {390, 4.572955}, {114, 4.5133986}, {1240, 4.477317}, {50, 4.4743624}, {408, 4.4618196}, {853, 4.4612164}, {455, 4.452915}, {171, 4.449279}, {89, 4.3644695}]         |\n","|6      |[{1643, 5.074277}, {483, 4.3744526}, {178, 4.343747}, {427, 4.3142514}, {1449, 4.2851486}, {480, 4.252022}, {603, 4.22822}, {493, 4.2239165}, {199, 4.204629}, {357, 4.199059}]         |\n","|9      |[{1643, 6.1961894}, {1218, 5.7026553}, {1160, 5.5183764}, {1467, 5.3271804}, {1131, 5.2956834}, {143, 5.266818}, {705, 5.259261}, {1144, 5.2042356}, {1064, 5.203186}, {1368, 5.182536}]|\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 5 rows\n","\n","+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|item_id|recommendations                                                                                                                                                                |\n","+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1      |[{688, 5.1495886}, {810, 5.0946317}, {849, 4.9875183}, {357, 4.935267}, {477, 4.826673}, {887, 4.805241}, {801, 4.7964916}, {523, 4.791944}, {939, 4.781163}, {507, 4.77961}]  |\n","|3      |[{813, 4.775132}, {50, 4.6938334}, {317, 4.6540956}, {366, 4.596555}, {636, 4.387526}, {551, 4.3864875}, {472, 4.3369637}, {324, 4.3154764}, {355, 4.2968826}, {760, 4.263777}]|\n","|5      |[{38, 4.905864}, {341, 4.764087}, {907, 4.6916018}, {939, 4.687662}, {89, 4.667772}, {507, 4.628379}, {427, 4.619819}, {36, 4.6123915}, {849, 4.5558796}, {628, 4.484474}]     |\n","|6      |[{98, 5.2233644}, {917, 5.030011}, {688, 4.960831}, {427, 4.912899}, {72, 4.8277407}, {174, 4.7574844}, {662, 4.7391667}, {252, 4.6761417}, {462, 4.5916204}, {572, 4.587419}] |\n","|9      |[{519, 5.3187404}, {270, 5.151785}, {928, 5.111938}, {98, 5.0953293}, {219, 4.9931164}, {909, 4.905758}, {252, 4.8881416}, {362, 4.871259}, {173, 4.860873}, {583, 4.8439755}] |\n","+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# YOUR CODE HERE by Hui Lin 04/02/2025\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","#--- STEP 1. setting up the ALS model\n","als = ALS(                     # Default parmameters for reference\n","    rank=10,                   # rank=10\n","    maxIter=15,                # maxIter=5\n","    regParam=0.1,              # regParam=0.01\n","    userCol=\"user_id\",\n","    itemCol=\"item_id\",\n","    ratingCol=\"rating\",\n","    implicitPrefs=False,       # implicit flag = False\n","    coldStartStrategy=\"drop\"   # coldStartStrategy=\"drop\"\n",")\n","\n","#--- STEP 2. train\n","model = als.fit(training)\n","\n","#---STEP 3. try to predict\n","predictions = model.transform(training)\n","\n","#---STEP 4. count RMSE for odel evaluation\n","evaluator = RegressionEvaluator(\n","    metricName=\"rmse\",\n","    labelCol=\"rating\",\n","    predictionCol=\"prediction\"\n",")\n","rmse = evaluator.evaluate(predictions)\n","print(f\"The RMSE is : {rmse}\")\n","\n","\n","# Generate top 10 movie recommendations for each user\n","userRecs = model.recommendForAllUsers(10)\n","userRecs.show(5, truncate=False)\n","\n","# Generate top 10 user recommendations for each movie\n","movieRecs = model.recommendForAllItems(10)\n","movieRecs.show(5, truncate=False)\n","\n"]},{"cell_type":"code","source":["#--- Generate top 10 movie recommendations for a specified set of users\n","users = full_data.select(als.getUserCol()).distinct().limit(5)\n","userSubsetRecs = model.recommendForUserSubset(users, 10)\n","userSubsetRecs.show(truncate=False)\n","\n","#--- Generate top 10 user recommendations for a specified set of movies\n","movies = full_data.select(als.getItemCol()).distinct().limit(5)\n","movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n","movieSubSetRecs.show(truncate=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYp3GxnLBEIk","executionInfo":{"status":"ok","timestamp":1743725049628,"user_tz":420,"elapsed":5344,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"fc2f3ca8-dc6e-47f1-e7e5-f9f804e5e1bb"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|user_id|recommendations                                                                                                                                                                       |\n","+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|471    |[{1278, 5.6420107}, {1664, 5.518168}, {793, 5.5140147}, {1152, 5.3391666}, {1167, 5.021873}, {832, 4.917868}, {973, 4.8987875}, {731, 4.790111}, {1612, 4.7761283}, {1160, 4.7238717}]|\n","|463    |[{1233, 4.7971663}, {1449, 4.3699713}, {1193, 4.275338}, {1466, 4.243907}, {19, 4.243059}, {863, 4.200204}, {1194, 4.177213}, {1426, 4.149211}, {272, 4.142291}, {100, 4.1375613}]    |\n","|833    |[{1368, 4.771521}, {1643, 4.652089}, {589, 4.4667}, {1512, 4.449094}, {320, 4.4426074}, {1597, 4.432933}, {1449, 4.4063644}, {488, 4.2973332}, {1187, 4.288962}, {346, 4.2757387}]    |\n","|496    |[{853, 4.8703995}, {253, 4.5418515}, {1240, 4.523105}, {899, 4.514208}, {1268, 4.359358}, {1388, 4.33728}, {1467, 4.276201}, {42, 4.258081}, {246, 4.255624}, {1005, 4.225565}]       |\n","|148    |[{1019, 5.2479663}, {115, 4.971517}, {1167, 4.8101397}, {168, 4.804834}, {50, 4.764535}, {1643, 4.7227383}, {1375, 4.695137}, {1269, 4.69104}, {497, 4.6074}, {1159, 4.588625}]       |\n","+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|item_id|recommendations                                                                                                                                                                   |\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|471    |[{688, 4.8046646}, {939, 4.7925873}, {907, 4.747318}, {849, 4.706195}, {628, 4.687276}, {89, 4.665558}, {507, 4.6263547}, {810, 4.607899}, {427, 4.5654025}, {324, 4.53023}]      |\n","|463    |[{68, 5.0499105}, {857, 4.9587755}, {810, 4.885648}, {239, 4.8406696}, {52, 4.6873264}, {174, 4.6498294}, {777, 4.641534}, {358, 4.606386}, {219, 4.5916204}, {686, 4.571151}]    |\n","|833    |[{688, 4.9984937}, {628, 4.669024}, {507, 4.6336827}, {811, 4.4957747}, {309, 4.4270606}, {130, 4.4048243}, {801, 4.306009}, {242, 4.296608}, {816, 4.224089}, {166, 4.2179418}]  |\n","|496    |[{810, 5.2409053}, {939, 5.1659346}, {821, 5.134803}, {152, 5.1186357}, {340, 5.084726}, {477, 5.0805593}, {849, 5.060163}, {38, 5.0454116}, {225, 5.0091324}, {907, 4.997068}]   |\n","|148    |[{688, 4.6939034}, {810, 4.6173267}, {907, 4.509192}, {939, 4.4802294}, {849, 4.4697566}, {357, 4.4197674}, {507, 4.3295355}, {261, 4.3198466}, {534, 4.293987}, {477, 4.2783604}]|\n","+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"TtR1xRvonxiO"},"source":["Now compute the RMSE on the test dataset.\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GP23Xkgwi0SD","executionInfo":{"status":"ok","timestamp":1743725061384,"user_tz":420,"elapsed":3726,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"201d80fd-cb2d-4b92-b286-28b5d414bd38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample test predictions:\n","+-------+-------+------+----------+\n","|user_id|item_id|rating|prediction|\n","+-------+-------+------+----------+\n","|    251|    148|     2| 3.2948759|\n","|    255|    833|     4|  3.381153|\n","|    321|    496|     4| 3.9380772|\n","|    108|    471|     2|  3.153609|\n","|    101|    471|     3| 3.2720203|\n","+-------+-------+------+----------+\n","only showing top 5 rows\n","\n","The RMSE on TEST dataset is: 0.9329\n","\n","Training RMSE: 0.7420 | Test RMSE: 0.9329\n"]}],"source":["# YOUR CODE HERE by Hui Lin 04/02/2025\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","#--- apply to test dataset\n","test_predictions = model.transform(test)\n","\n","#--- take a look\n","print(\"Sample test predictions:\")\n","test_predictions.select(\"user_id\", \"item_id\", \"rating\", \"prediction\").show(5)\n","\n","\n","#--- get the RMSE\n","evaluator = RegressionEvaluator(\n","    metricName=\"rmse\",\n","    labelCol=\"rating\",\n","    predictionCol=\"prediction\"\n",")\n","\n","test_rmse = evaluator.evaluate(test_predictions)\n","print(f\"The RMSE on TEST dataset is: {test_rmse:.4f}\")\n","\n","\n","#--- try to compare\n","train_predictions = model.transform(training)\n","train_rmse = evaluator.evaluate(train_predictions)\n","print(f\"\\nTraining RMSE: {train_rmse:.4f} | Test RMSE: {test_rmse:.4f}\")\n"]},{"cell_type":"code","source":["# try to decrease the RMSE on test dataset\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","als = ALS(\n","    userCol=\"user_id\",\n","    itemCol=\"item_id\",\n","    ratingCol=\"rating\",\n","    coldStartStrategy=\"drop\"\n",")\n","\n","# set up the scale\n","param_grid = ParamGridBuilder()\\\n","            .addGrid(als.rank, [10, 15]) \\\n","            .addGrid(als.regParam, [0.05, 0.1])\\\n","            .addGrid(als.maxIter, [10, 15])\\\n","            .build()\n","\n","evaluator = RegressionEvaluator(\n","    metricName=\"rmse\",\n","    labelCol=\"rating\",\n","    predictionCol=\"prediction\"\n",")\n","\n","cv = CrossValidator(\n","    estimator=als,\n","    estimatorParamMaps=param_grid,\n","    evaluator=evaluator,\n","    numFolds=3,\n","    parallelism=4\n",")\n","\n","print(\"Begin to adjust parameters...\")\n","cv_model = cv.fit(training)\n","best_model = cv_model.bestModel\n","\n","print(\"=== the best parameter combination ===\")\n","print(f\"Rank: {best_model.rank}\")\n","print(f\"RegParam: {best_model._java_obj.parent().getRegParam()}\")\n","print(f\"MaxIter: {best_model._java_obj.parent().getMaxIter()}\")\n","\n","test_predictions = best_model.transform(test)\n","test_rmse = evaluator.evaluate(test_predictions)\n","print(f\"RMSE on test: {test_rmse:.4f}\")\n","\n","#--- try to compare\n","original_predictions = model.transform(test)\n","original_rmse = evaluator.evaluate(original_predictions)\n","print(f\"orginal RMSE: {original_rmse:.4f}\")\n","print(f\"RMSE decrease: {original_rmse - test_rmse:.4f}\")\n","\n","#--- check the overfitting on train dataset\n","train_predictions = best_model.transform(training)\n","train_rmse = evaluator.evaluate(train_predictions)\n","print(f\"traning RMSE: {train_rmse:.4f} | test RMSE: {test_rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS_AP9m0Cz4y","executionInfo":{"status":"ok","timestamp":1743725001534,"user_tz":420,"elapsed":141363,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"dbc6e085-2080-4c9d-abfc-abec1fb46caf"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Begin to adjust parameters...\n","=== the best parameter combination ===\n","Rank: 10\n","RegParam: 0.1\n","MaxIter: 15\n","RMSE on test: 0.9329\n","orginal RMSE: 1.1264\n","RMSE decrease: 0.1936\n","traning RMSE: 0.7420 | test RMSE: 0.9329\n"]}]},{"cell_type":"markdown","metadata":{"id":"lBvSaWGEMHXI"},"source":["At this point, you can use the trained model to produce the top-K recommendations for each user. You have to produce the title of top movies, not just the ids"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbMlWL5_UfSc","executionInfo":{"status":"ok","timestamp":1743725364737,"user_tz":420,"elapsed":9273,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"bcb04755-9e34-4e75-a397-a6eccb80d2eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Top 5 movie recommendations for users:\n","+-------+-------+--------------------------------------------------------------------+---------+\n","|user_id|item_id|movie                                                               |rating   |\n","+-------+-------+--------------------------------------------------------------------+---------+\n","|1      |1449   |Pather Panchali (1955)                                              |4.9319506|\n","|1      |1368   |Mina Tannenbaum (1994)                                              |4.8544674|\n","|1      |169    |Wrong Trousers, The (1993)                                          |4.8379045|\n","|1      |119    |Maya Lin: A Strong Clear Vision (1994)                              |4.817549 |\n","|1      |408    |Close Shave, A (1995)                                               |4.804264 |\n","|2      |1449   |Pather Panchali (1955)                                              |5.0798025|\n","|2      |1643   |Angel Baby (1995)                                                   |4.919994 |\n","|2      |318    |Schindler's List (1993)                                             |4.873684 |\n","|2      |863    |Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)|4.845086 |\n","|2      |1194   |Once Were Warriors (1994)                                           |4.803956 |\n","+-------+-------+--------------------------------------------------------------------+---------+\n","only showing top 10 rows\n","\n"]}],"source":["# YOUR CODE HERE by Hui Lin 04/02/2025\n","from pyspark.sql.functions import explode\n","\n","#--- set the recommendation top five\n","TOP_K = 5\n","\n","#--- generate recommendation list for all user\n","user_recs = model.recommendForAllUsers(TOP_K)\n","\n","#--- unfold the list\n","user_recs_expanded = user_recs.select(\n","    \"user_id\",\n","    explode(\"recommendations\").alias(\"recommendation\")\n",").select(\n","    \"user_id\",\n","    \"recommendation.item_id\",\n","    \"recommendation.rating\"\n",")\n","\n","#--- match the movie name\n","recommendations_with_titles = user_recs_expanded.join(\n","    items,\n","    \"item_id\"\n",").select(\n","    \"user_id\",\n","    \"item_id\",\n","    \"movie\",\n","    \"rating\"\n",").orderBy(\n","    \"user_id\",\n","    col(\"rating\").desc()\n",")\n","\n","#--- show the result\n","print(f\"Top {TOP_K} movie recommendations for users:\")\n","recommendations_with_titles.show(n=10, truncate=False)\n","\n","#--- save the result\n","recommendations_with_titles.coalesce(1).write.csv(\n","    path=\"movie_recommendations\",\n","    mode=\"overwrite\",\n","    header=True\n",")\n"]},{"cell_type":"markdown","source":["Add your own ratings to the dataset and use the model to produce top-K recommendations for yourself.\n","\n","These are the steps that you need to take:\n","\n","\n","1.   Search the dataset for movies that you have watched before. You need the ids of those movies\n","2.   Add your ratings to the training dataset. You need to generate a unique user_id for yourself (a user_id that does not already exist in the dataset).\n","3.   Train the model using the new dataset.\n","4.   Produce top-K recommendation for youself.\n","\n"],"metadata":{"id":"gQvT7_qsB2QA"}},{"cell_type":"code","source":["# YOUR CODE HERE by Hui Lin 04/02/2025\n","#=== STEP1: Search the dataset for movies that you have watched before.\n","# 1240    Ghost in the Shell (Kokaku kidotai) (1995)\n","# 853     Braindead (1992)\n","# 902     Big Lebowski, The (1998)\n","# 251     Shall We Dance? (1996)\n","# 313     Titanic (1997)\n","# 1019    Die xue shuang xiong (Killer, The) (1989)\n","# 914     Wild Things (1998)\n","# 1483    Man in the Iron Mask, The (1998)\n","\n","#=== STEP2: Add your ratings to the training dataset.\n","# assumed id = 967\n","\n","from pyspark.sql import Row\n","from pyspark.sql.functions import col\n","\n","#--- check user id if exist\n","if(training.filter(training.user_id == 967).count() > 0):\n","    print(\"warning：user_id 967 already existed！\")\n","\n","# 2. 准备要插入的评分数据\n","new_ratings = [\n","    (1240, 5),\n","    (853, 5),\n","    (902, 2),\n","    (251, 3),\n","    (313, 5),\n","    (1019, 4),\n","    (914, 4),\n","    (1483, 3)\n","]\n","\n","new_records = sc.parallelize([\n","    Row(user_id=967, item_id=item_id, rating=rating, timestamp=1743638400)\n","    for item_id, rating in new_ratings\n","])\n","\n","new_ratings_df = spark.createDataFrame(new_records)\n","updated_training = training.unionByName(new_ratings_df)\n","\n","#--- take a look\n","print(f\"original train records: {training.count()}\")\n","print(f\"newadd record: {len(new_ratings)}\")\n","print(f\"updated train records: {updated_training.count()}\")\n","\n","print(\"newadd sample：\")\n","updated_training.filter(col(\"user_id\") == 967).show()\n","\n","updated_training.write.mode(\"overwrite\").csv(\"updated_training\", header=True)\n","\n"],"metadata":{"id":"POHVCFQbB_I_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743727559213,"user_tz":420,"elapsed":3966,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"90b4ddc4-7549-4c18-9940-eb2b4e680eb8"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["original train records: 80000\n","newadd record: 8\n","updated train records: 80008\n","newadd sample：\n","+-------+-------+------+----------+\n","|user_id|item_id|rating| timestamp|\n","+-------+-------+------+----------+\n","|    967|   1240|     5|1743638400|\n","|    967|    853|     5|1743638400|\n","|    967|    902|     2|1743638400|\n","|    967|    251|     3|1743638400|\n","|    967|    313|     5|1743638400|\n","|    967|   1019|     4|1743638400|\n","|    967|    914|     4|1743638400|\n","|    967|   1483|     3|1743638400|\n","+-------+-------+------+----------+\n","\n"]}]},{"cell_type":"code","source":["#=== STEP3: Train the model using the new dataset.\n","\n","new_model = als.fit(updated_training)\n","\n","new_predictions = new_model.transform(full_data)\n","\n","#---count RMSE\n","evaluator = RegressionEvaluator(\n","    metricName=\"rmse\",\n","    labelCol=\"rating\",\n","    predictionCol=\"prediction\"\n",")\n","rmse = evaluator.evaluate(new_predictions)\n","print(f\"The new RMSE is : {rmse}\")\n","\n","\n"],"metadata":{"id":"uiqE1D9cM50c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743728059017,"user_tz":420,"elapsed":9426,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"b6deb7e9-14ac-4f6a-86d0-7046f7f22ed5"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["The new RMSE is : 0.7838161246739472\n"]}]},{"cell_type":"code","source":["#=== STEP4: Produce top-K recommendation for youself.\n","\n","from pyspark.sql.functions import explode, col\n","\n","#--- generate list\n","my_recs = new_model.recommendForUserSubset(\n","    spark.createDataFrame([(967,)]).toDF(\"user_id\"),\n","    10\n",")\n","\n","#--- find the movie already rated\n","rated_movies = updated_training.filter(col(\"user_id\") == 967) \\\n","                             .select(\"item_id\").rdd.flatMap(lambda x: x).collect()\n","\n","\n","#--- unfold the list\n","my_recs_expanded = my_recs.select(\n","    \"user_id\",\n","    explode(\"recommendations\").alias(\"recommendation\")\n",").select(\n","    \"user_id\",\n","    \"recommendation.item_id\",\n","    \"recommendation.rating\"\n",")\n","\n","#--- skip the rated one, and match the movie name\n","newlist_with_titles = my_recs_expanded.join(\n","    items,\n","    \"item_id\") \\\n","    .filter(~col(\"item_id\").isin(rated_movies)\n",").select(\n","    \"user_id\",\n","    \"item_id\",\n","    \"movie\",\n","    \"rating\"\n",").orderBy(\n","    \"user_id\",\n","    col(\"rating\").desc()\n",")\n","\n","\n","#--- show the result\n","print(f\"Top {TOP_K} movie recommendations for Hui Lin:\")\n","newlist_with_titles.show(n=TOP_K,truncate=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCZNboZURDyt","executionInfo":{"status":"ok","timestamp":1743728704431,"user_tz":420,"elapsed":2308,"user":{"displayName":"林辉","userId":"00815086233424508369"}},"outputId":"731bc5e8-f1e1-4fa6-9ff0-dd9626bcab5a"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 5 movie recommendations for Hui Lin:\n","+-------+-------+---------------------------------------+---------+\n","|user_id|item_id|movie                                  |rating   |\n","+-------+-------+---------------------------------------+---------+\n","|967    |899    |Winter Guest, The (1997)               |5.040983 |\n","|967    |1233   |N�nette et Boni (1996)                 |4.86052  |\n","|967    |1467   |Saint of Fort Washington, The (1993)   |4.7092147|\n","|967    |64     |Shawshank Redemption, The (1994)       |4.508607 |\n","|967    |904    |Ma vie en rose (My Life in Pink) (1997)|4.433173 |\n","+-------+-------+---------------------------------------+---------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","source":["### Report for Assignment 7"],"metadata":{"id":"Tg1wg-CFWNPo"}},{"cell_type":"markdown","source":["This assignment involved building a collaborative filtering recommendation system using Spark’s ALS algorithm on the MovieLens dataset.\n","\n","The experimental process is recorded as follows:\n","\n","1. After obtaining the experimental data, I conducted preliminary analysis and inspection, including the order of magnitude, numerical integrity, value range, numerical distribution statistics, etc.\n","\n","2. Perform ALS training: I first use the default parameter configuration in the tutorial, and then use Cross Validator to repeatedly train and adjust the optimization parameters to obtain the parameter combination that minimizes the RMSE value.\n","Implementation results:\n","(Rank: 10, RegParam: 0.1, MaxIter: 15), RMSE dropped from initial 1.1264 to 0.9329.\n","\n","3. I make predictions based on the optimization model and create a Top-K movie recommendation list. And verify the reliability of the recommended model through my own empirical values.\n","Here I select 10 movies that have been watched, added custom ratings for 8 of them to simulate cold-start scenarios. Used recommendForUserSubset to generate top-K recommendations, and from the final recommendation list, hit 1 favorite movie (eg:Shawshank Redemption). This result  verifies that the recommended model is effective.\n","\n","To sum up, This assignment exercise strengthens the matrix decomposition and Collaborative Filtering knowledge points introduced in the class, reducing prediction errors through parameter adjustments and producing feasible recommendation results. In real life applications, more attention should be paid to the exploration of potential factors.\n"],"metadata":{"id":"gwAswmopWSwi"}}],"metadata":{"colab":{"provenance":[{"file_id":"1syE01xsWlyyoaLrxJwgAa7AkFlAFc18a","timestamp":1743653626967},{"file_id":"1UWeDiyXiwDDqe7ksN2kt-myHsuSLObv8","timestamp":1679170761356}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}